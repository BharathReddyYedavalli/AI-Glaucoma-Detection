{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9905ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  scikit-learn pandas matplotlib tqdm gradio\n",
    "# !pip install kagglehub\n",
    "# !pip[ install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4627792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Misc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "\n",
    "# Subject to change\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bbbdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded at: C:\\Users\\bhara\\.cache\\kagglehub\\datasets\\bharathry\\glaucoma-dataset-for-ai-diagnosis-v2\\versions\\1\n",
      "Current Data Dir: C:\\Users\\bhara\\.cache\\kagglehub\\datasets\\bharathry\\glaucoma-dataset-for-ai-diagnosis-v2\\versions\\1\\Glaucoma Dataset for AI Diagnosis\n",
      "Top-Level Folders: ['glaucoma', 'normal']\n",
      "Train samples: 2527\n",
      "Val samples: 632\n"
     ]
    }
   ],
   "source": [
    "# Function to find imaghes because I have a custom folder structure that is hard to load directly\n",
    "def find_images(folder_path, label):\n",
    "    images = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            images.append((os.path.join(folder_path, file), label))\n",
    "    return images\n",
    "\n",
    "data_dir = kagglehub.dataset_download(\"bharathry/glaucoma-dataset-for-ai-diagnosis-v2\")\n",
    "print(\"Downloaded at:\", data_dir)\n",
    "\n",
    "# Point to the actual subfolder that contains glaucoma/ and normal/ because the dataset is nested with folders\n",
    "data_dir = os.path.join(data_dir, \"Glaucoma Dataset for AI Diagnosis\")\n",
    "print(\"Current Data Dir:\", data_dir)\n",
    "print(\"Top-Level Folders:\", os.listdir(data_dir))\n",
    "\n",
    "glaucoma_images = find_images(os.path.join(data_dir, \"glaucoma\"), 1)\n",
    "normal_images = find_images(os.path.join(data_dir, \"normal\"), 0)\n",
    "\n",
    "all_images = glaucoma_images + normal_images\n",
    "\n",
    "# Stratified train/val split because we have an imbalanced dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(all_images)),\n",
    "    test_size=0.2,\n",
    "    stratify=[label for _, label in all_images],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_split = [all_images[i] for i in train_idx]\n",
    "val_split = [all_images[i] for i in val_idx]\n",
    "\n",
    "print(\"Train samples:\", len(train_split))\n",
    "print(\"Val samples:\", len(val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ffbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class I creasted to traverse the custom folder structure properly\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.image_list[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Augmented transform for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Simpler transform for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_split, transform=train_transform)\n",
    "val_dataset = CustomDataset(val_split, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe51dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bhara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\bhara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained MobileNetV3 model so I can train it on my custom dataset\n",
    "model = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "model.classifier[2] = nn.Dropout(p=0.4)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee52fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/79 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\mobilenetv3.py:220\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\mobilenetv3.py:210\u001b[0m, in \u001b[0;36mMobileNetV3._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\batchnorm.py:173\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    175\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "EPOCHS = 30\n",
    "PATIENCE = 5 # Early stopping patience, I need this because my model overfits quickly and easily on my dataset even after augmenting it\n",
    "\n",
    "# These next four lines were so I could make graphs for training and validation losses and accuracies\n",
    "# I don't need to change these, but I will leave them here for reference\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "all_val_preds_by_epoch = []\n",
    "all_val_labels_by_epoch = []\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_weights = None\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    epoch_val_preds = []\n",
    "    epoch_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            epoch_val_preds.extend(preds.cpu().numpy())\n",
    "            epoch_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # Store epoch-wise predictions\n",
    "    all_val_preds_by_epoch.append(epoch_val_preds)\n",
    "    all_val_labels_by_epoch.append(epoch_val_labels)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: \"\n",
    "        f\"Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.2f}% | \"\n",
    "        f\"Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.2f}%\"\n",
    "    )\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_weights = model.state_dict()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= PATIENCE:\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_weights)\n",
    "torch.save(best_weights, \"best_glaucoma_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bf736",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mall_val_labels_by_epoch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, all_val_preds_by_epoch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     26\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlaucoma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, values_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mgca())\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_range, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs_range, val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(epochs_range, val_accuracies, label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.subplot(1, 3, 3)\n",
    "cm = confusion_matrix(epoch_val_labels, epoch_val_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Glaucoma\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\", ax=plt.gca())\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"glaucoma_results.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def generate_gradcam(model, image_tensor, target_class, device):\n",
    "    model.eval()\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Hook the gradients of the target layer\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    target_layer = model.features[-1]\n",
    "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    output = model(image_tensor)\n",
    "    class_score = output[0, target_class]\n",
    "    model.zero_grad()\n",
    "    class_score.backward()\n",
    "\n",
    "    # Cleanup hooks\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()\n",
    "\n",
    "    # Compute weights\n",
    "    grad = gradients[0]\n",
    "    act = activations[0]\n",
    "    pooled_grad = torch.mean(grad, dim=[0, 2, 3])\n",
    "    weighted_act = (act[0] * pooled_grad[:, None, None]).sum(dim=0)\n",
    "\n",
    "    # Normalize heatmap\n",
    "    heatmap = weighted_act.cpu().detach().numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap) + 1e-8\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Save the best model weights\n",
    "torch.save(best_weights, \"best_glaucoma_model.pth\")\n",
    "print(\"Best model weights saved to best_glaucoma_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def overlay_gradcam_on_image(image_tensor, heatmap):\n",
    "    image_np = F.to_pil_image(image_tensor.cpu()).convert(\"RGB\")\n",
    "    image_np = np.array(image_np)\n",
    "\n",
    "    # Resize heatmap to match image size\n",
    "    heatmap_resized = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Overlay heatmap on image\n",
    "    overlayed_img = cv2.addWeighted(image_np, 0.6, heatmap_color, 0.4, 0)\n",
    "    return overlayed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh best_glaucoma_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": []\n",
    "}\n",
    "\n",
    "# Compute metrics per epoch\n",
    "for epoch_preds, epoch_labels in zip(all_val_preds_by_epoch, all_val_labels_by_epoch):\n",
    "    val_metrics[\"accuracy\"].append(accuracy_score(epoch_labels, epoch_preds))\n",
    "    val_metrics[\"recall\"].append(recall_score(epoch_labels, epoch_preds))\n",
    "    val_metrics[\"f1_score\"].append(f1_score(epoch_labels, epoch_preds))\n",
    "\n",
    "# Plot them\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(val_metrics[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_metrics[\"recall\"], label=\"Recall\", color=\"orange\")\n",
    "plt.title(\"Validation Recall\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_metrics[\"f1_score\"], label=\"F1 Score\", color=\"green\")\n",
    "plt.title(\"Validation F1 Score\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
